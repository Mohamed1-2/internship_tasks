{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg8l-2Yb0tAX"
      },
      "source": [
        "## **Impost necessary liberties** 🔳 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zk6EwWh04_F",
        "outputId": "7e08bfda-64af-4a23-9a02-b3ab0869085c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.7/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.5.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.47.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.1.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==1.13.1\n",
        "#%tensorflow_version 1.x\n",
        "!pip install --upgrade h5py==2.10.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1MjKUa71LnN",
        "outputId": "1a22a097-c2fc-4370-d888-d1cc57bf0dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.7/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (21.3)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (9.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr-ind is already the newest version (4.00~git24-0e00fe6-1.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install pytesseract\n",
        "!sudo apt-get install tesseract-ocr-ind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_VU1gzrB0u8",
        "outputId": "97d077e3-a3a1-42af-bfd5-cc974388305e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.7/dist-packages (1.13.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.47.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.2.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.5.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.8.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==1.13.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X23lpQ8C-Ca",
        "outputId": "4f73a4ff-7375-4778-b32a-1f1670ab8ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3qcOm9DERMk",
        "outputId": "1698f3d3-b0f1-4e81-96a5-12ede3aee5e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-probability in /root/.local/lib/python3.7/site-packages (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (1.5.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (0.1.7)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (1.2.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (0.5.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --user --upgrade tensorflow-probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnVn39ZX1a6K"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from pytesseract import Output\n",
        "import cv2\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import glob\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLMYSDOm8Ud1"
      },
      "source": [
        "# Train MAsk RCNN Model for Card Detection 💪"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qIlUpIhTTKX"
      },
      "source": [
        "▶ change the dir to MaskRcnn model dir "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enHpmxeFT472",
        "outputId": "29a328cc-a110-4801-94aa-ad8cb016047d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Mask-R-CNN/Mask_RCNN-master\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/Mask-R-CNN/Mask_RCNN-master"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt5Qy30WUaF8"
      },
      "source": [
        "▶ Install Keras ver 2.0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asfk2PUAUhW8",
        "outputId": "c75ab4b4-8b03-44e2-ae36-a5bde0ed593b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras==2.0.8 in /usr/local/lib/python3.7/dist-packages (2.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (6.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.7.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras==2.0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o85VfsqBUnN-"
      },
      "source": [
        "▶ Import MaskRCNN files "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "745pmgfpUUGw"
      },
      "outputs": [],
      "source": [
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvvy4IuA85sk"
      },
      "source": [
        "▶ Helper Functions "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B49To-NE88e6"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(utils.Dataset):\n",
        "\n",
        "    def load_custom(self, annotation_json, images_dir, dataset_type=\"train\"):\n",
        "        \"\"\" Load the coco-like dataset from json\n",
        "        Args:\n",
        "            annotation_json: The path to the coco annotations json file\n",
        "            images_dir: The directory holding the images referred to by the json file\n",
        "        \"\"\"\n",
        "\n",
        "        # Load json from file\n",
        "        json_file = open(annotation_json)\n",
        "        coco_json = json.load(json_file)\n",
        "        json_file.close()\n",
        "\n",
        "\n",
        "        # Add the class names using the base method from utils.Dataset\n",
        "        source_name = \"coco_like\"\n",
        "        for category in coco_json['categories']:\n",
        "            class_id = category['id']\n",
        "\n",
        "            class_name = category['name']\n",
        "            if class_id < 1:\n",
        "                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(\n",
        "                    class_name))\n",
        "                return\n",
        "\n",
        "            self.add_class(source_name, class_id, class_name)\n",
        "\n",
        "        # Get all annotations\n",
        "        annotations = {}\n",
        "        for annotation in coco_json['annotations']:\n",
        "            image_id = annotation['image_id']\n",
        "            if image_id not in annotations:\n",
        "                annotations[image_id] = []\n",
        "            annotations[image_id].append(annotation)\n",
        "\n",
        "        # Get all images and add them to the dataset\n",
        "        seen_images = {}\n",
        "\n",
        "        # Split the dataset, if train, get 90%, else 10%\n",
        "        len_images = len(coco_json['images'])\n",
        "        if dataset_type == \"train\":\n",
        "            img_range = [int(len_images / 9), len_images]\n",
        "        else:\n",
        "            img_range = [0, int(len_images / 9)]\n",
        "\n",
        "        for i in range(img_range[0], img_range[1]):\n",
        "            image = coco_json['images'][i]\n",
        "            image_id = image['id']\n",
        "            if image_id in seen_images:\n",
        "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
        "            else:\n",
        "                seen_images[image_id] = image\n",
        "                try:\n",
        "                    image_file_name = image['file_name']\n",
        "                    image_width = image['width']\n",
        "                    image_height = image['height']\n",
        "                except KeyError as key:\n",
        "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
        "\n",
        "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n",
        "                image_annotations = annotations[image_id]\n",
        "\n",
        "                # Add the image using the base method from utils.Dataset\n",
        "                self.add_image(\n",
        "                    source=source_name,\n",
        "                    image_id=image_id,\n",
        "                    path=image_path,\n",
        "                    width=image_width,\n",
        "                    height=image_height,\n",
        "                    annotations=image_annotations\n",
        "                )\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\" Load instance masks for the given image.\n",
        "        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\n",
        "        Args:\n",
        "            image_id: The id of the image to load masks for\n",
        "        Returns:\n",
        "            masks: A bool array of shape [height, width, instance count] with\n",
        "                one mask per instance.\n",
        "            class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        image_info = self.image_info[image_id]\n",
        "        annotations = image_info['annotations']\n",
        "        instance_masks = []\n",
        "        class_ids = []\n",
        "\n",
        "        for annotation in annotations:\n",
        "            class_id = annotation['category_id']\n",
        "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
        "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
        "            for segmentation in annotation['segmentation']:\n",
        "                mask_draw.polygon(segmentation, fill=1)\n",
        "                bool_array = np.array(mask) > 0\n",
        "                instance_masks.append(bool_array)\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "        mask = np.dstack(instance_masks)\n",
        "        class_ids = np.array(class_ids, dtype=np.int32)\n",
        "        #print(\"Class_ids, \", class_ids)\n",
        "        return mask, class_ids\n",
        "\n",
        "    def count_classes(self):\n",
        "        class_ids = set()\n",
        "        for image_id in self.image_ids:\n",
        "            image_info = self.image_info[image_id]\n",
        "            annotations = image_info['annotations']\n",
        "\n",
        "            for annotation in annotations:\n",
        "                class_id = annotation['category_id']\n",
        "                class_ids.add(class_id)\n",
        "\n",
        "        class_number = len(class_ids)\n",
        "        return class_number\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "def load_image_dataset(annotation_path, data_path, dataset_type):\n",
        "    train_data = CustomDataset()\n",
        "    train_data.load_custom(annotation_path, data_path, dataset_type)\n",
        "    train_data.prepare()\n",
        "    return train_data\n",
        "class myMaskRCNNConfig(Config):\n",
        "    # give the configuration a recognizable name\n",
        "    NAME = \"MaskRCNN_config\"\n",
        "\n",
        "    # set the number of GPUs to use along with the number of images\n",
        "    # per GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "    # number of classes (we would normally add +1 for the background)\n",
        "    # fire name + last name + gender + card no + date of birth + BG\n",
        "    NUM_CLASSES = 1 + 1\n",
        "\n",
        "    # Number of training steps per epoch\n",
        "    STEPS_PER_EPOCH = 100\n",
        "\n",
        "    # Learning rate\n",
        "    LEARNING_RATE = 0.001\n",
        "\n",
        "    # Skip detections with < 90% confidence\n",
        "    DETECTION_MIN_CONFIDENCE = 0.90\n",
        "\n",
        "    # setting Max ground truth instances\n",
        "    MAX_GT_INSTANCES = 1\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 512\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPq1BIUs8nTa"
      },
      "source": [
        "▶ Load the dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdGGXoB73G5T",
        "outputId": "c0f0defb-7c55-443a-c87f-00c16dc39bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 15\n",
            "test: 1\n",
            "Classes: 1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train = load_image_dataset(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/id_detection/annotation/logo_an.json\"), \"/content/drive/MyDrive/Colab Notebooks/id_detection/train\", \"train\")\n",
        "test = load_image_dataset(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/id_detection/annotation/logo_an.json\"), \"/content/drive/MyDrive/Colab Notebooks/id_detection/train\", \"test\")\n",
        "class_number = train.count_classes()\n",
        "print('Train: %d' % len(train.image_ids))\n",
        "print('test: %d' % len(test.image_ids))\n",
        "print(\"Classes: {}\".format(class_number))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F7SndFtFSwE"
      },
      "source": [
        "▶ train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aKMXgTj28sno",
        "outputId": "cbdba826-c9ae-435a-ca92-317a033cd7a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/mask_rcnn_coco.h5\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/drive/MyDrive/Colab Notebooks/Mask-R-CNN/Mask_RCNN-master/new_model_28/maskrcnn_config20220902T0955/mask_rcnn_maskrcnn_config_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "Epoch 1/4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n",
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  1/100 [..............................] - ETA: 6038s - loss: 8.3870 - rpn_class_loss: 0.0625 - rpn_bbox_loss: 5.0840 - mrcnn_class_loss: 1.2784 - mrcnn_bbox_loss: 1.4880 - mrcnn_mask_loss: 0.4741"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py:830: FutureWarning: Input image dtype is bool. Interpolation is not defined with bool data type. Please set order to 0 or explicitely cast input image to another data type. Starting from version 0.19 a ValueError will be raised instead of this warning.\n",
            "  order = _validate_interpolation_order(image.dtype, order)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-72188fedb70c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         layers='heads')\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/Mask-R-CNN/Mask_RCNN-master/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2372\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m         )\n\u001b[1;32m   2376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "                                                                     \n",
        "# save logs and trained model\n",
        "model_dir= \"/content/drive/MyDrive/Colab Notebooks/Mask-R-CNN/Mask_RCNN-master/new_model_28\"\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = \"/content/drive/MyDrive/Colab Notebooks/mask_rcnn_coco.h5\"\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "\n",
        "config = myMaskRCNNConfig()\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                          model_dir=model_dir)\n",
        "init_with = \"coco\"  # imagenet, coco, or last\n",
        "\n",
        "if init_with == \"imagenet\":\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "elif init_with == \"coco\":\n",
        "    print(COCO_MODEL_PATH)\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                        exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "elif init_with == \"last\":\n",
        "    # Load the last model you trained and continue training\n",
        "    model.load_weights(model.find_last(), by_name=True)\n",
        "\n",
        "\n",
        "# train the model\n",
        "model.train(train, test,\n",
        "        learning_rate=config.LEARNING_RATE,\n",
        "        epochs=4,\n",
        "        layers='heads')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC4QcZEvSrSF"
      },
      "source": [
        "## **Card Detection Model 🔍 🎴**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzPuA5CWU7Eu"
      },
      "source": [
        "▶ Create configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPH9DhUWElZZ",
        "outputId": "6d7376b0-7176-48f2-b26d-9c562e04bc0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Colab Notebooks/Mask-R-CNN/Mask_RCNN-master/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights from  /content/drive/MyDrive/Colab Notebooks/Mask-R-CNN/Mask_RCNN-master/new_model_28/maskrcnn_config20220902T0455/mask_rcnn_maskrcnn_config_0003.h5\n",
            "Re-starting from epoch 3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def load_model():\n",
        "    config = myMaskRCNNConfig()\n",
        "\n",
        "\n",
        "    # Recreate the model in inference mode\n",
        "    model = modellib.MaskRCNN(mode=\"inference\",\n",
        "                              config=config,\n",
        "                              model_dir=\"/content/drive/MyDrive/Colab Notebooks/Mask-R-CNN/Mask_RCNN-master/new_model_28\")\n",
        "\n",
        "    # Get path to saved weights\n",
        "    # Either set a specific path or find last trained weights\n",
        "    #model With 2 epochs \n",
        "    #model_path = os.path.abspath(\"/content/drive/MyDrive/Colab Notebooks/Mask-R-CNN/Mask_RCNN-master/new_model_28/maskrcnn_config20220828T1213/mask_rcnn_maskrcnn_config_0001.h5\")\n",
        "    model_path = os.path.abspath(\"/content/drive/MyDrive/Colab Notebooks/Mask-R-CNN/Mask_RCNN-master/new_model_28/maskrcnn_config20220902T0455/mask_rcnn_maskrcnn_config_0003.h5\")\n",
        "    #model_path = model.find_last()\n",
        "\n",
        "    # Load trained weights\n",
        "    print(\"Loading weights from \", model_path)\n",
        "    model.load_weights(model_path, by_name=True)\n",
        "    return model, config\n",
        "\n",
        "model, inference_config =load_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFATVlNilvhy"
      },
      "source": [
        "▶ Test the model  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXk1GbuD1E4j"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image # Notice the 'from PIL' at the start of the line\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i59FH3vxfht7"
      },
      "outputs": [],
      "source": [
        "\n",
        "for imagePath in glob.glob(\"/content/drive/MyDrive/Colab Notebooks/id_detection/test\"+ \"/*.jpeg\"):\n",
        "    image = cv2.imread(imagePath)\n",
        "    (h,w)=image.shape[:2]\n",
        "    img = img_to_array(image)\n",
        "    # detecting objects in the image\n",
        "    result= model.detect([img])\n",
        "    r = result[0]\n",
        "    Detection_text=\"Not Detected\"\n",
        "    color = (0, 0, 255)\n",
        "    class_name=\"western digital id\"\n",
        "    found = None\n",
        "    if r[\"scores\"].any():\n",
        "      color = (125, 246, 55)\n",
        "      Detection_text=\"Detected\"\n",
        "      an_array = np.array(r[\"scores\"])\n",
        "      index = np.argmax(an_array)\n",
        "      y1, x1, y2, x2=tuple(r[\"rois\"][index])\n",
        "      #visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'], test.class_names, r['scores'],title=\"Predictions\")\n",
        "      score = round(r[\"scores\"][index], 2)\n",
        "      text=str(class_name +\"  \"+str(score))\n",
        "      cv2.putText(img,text,(x1, y1 - 15),cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "      cv2.rectangle(img, (x1, y1), (x2, int(y2*3)), (0, 0, 255), 2) # big bbox\n",
        "      #cv2.rectangle(img, (x1, y1), (x2, int(y2)), (0, 0, 255), 2)\n",
        "    cv2.putText(img, Detection_text, (0 + int(w/45),0 + int(h/17.5)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
        "    cv2_imshow(img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFyNvR-aJUtM"
      },
      "source": [
        "## **ID Card detaction** 🆔 🕵"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpweuaH2b4lb",
        "outputId": "281cd360-8f0d-4c49-f35c-67f2ecf351a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-08-28 17:11:18--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  16.6MB/s    in 16s     \n",
            "\n",
            "2022-08-28 17:11:35 (14.7 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKd7U4AlJrRz"
      },
      "outputs": [],
      "source": [
        "classes = None\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/id_detection/coco.names.txt\", \"r\") as f:\n",
        "  classes = [line.strip() for line in f.readlines()]\n",
        "Card_detected=\"Not Detected\"\n",
        "color = (0, 0, 255)\n",
        "id_numbers_detected=\"Not Detected\"\n",
        "color2 = (0, 0, 255)\n",
        "\n",
        "\n",
        "net = cv2.dnn.readNet('/content/drive/MyDrive/Colab Notebooks/Mask-R-CNN/Mask_RCNN-master/yolov3.weights', '/content/drive/MyDrive/Colab Notebooks/id_detection/yolov3.cfg.txt')\n",
        "for imagePath in glob.glob(\"/content/drive/MyDrive/Colab Notebooks/id_detection/test\"+ \"/*.jpeg\"):\n",
        "    image = cv2.imread(imagePath)\n",
        "    (h,w)=image.shape[:2]\n",
        "    img = img_to_array(image)\n",
        "    # detecting objects in the image\n",
        "    result= model.detect([img])\n",
        "    r = result[0]\n",
        "    print(r)\n",
        "    class_name=\"western digital id\"\n",
        "    found = None\n",
        "    if r[\"scores\"].any():\n",
        "      Card_detected=\"Detected\"\n",
        "      color = (125, 246, 55)\n",
        "      Detection_text=\"Detected\"\n",
        "      an_array = np.array(r[\"scores\"])\n",
        "      index = np.argmax(an_array)\n",
        "      y1, x1, y2, x2=tuple(r[\"rois\"][index])\n",
        "      logo_imgCrop = image[y1:y2*3, x1:x2]\n",
        "      cv2_imshow(logo_imgCrop)\n",
        "      #visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'], test.class_names, r['scores'],title=\"Predictions\")\n",
        "      score = round(r[\"scores\"][index]*100, 2) \n",
        "      text=str(class_name +\"  \"+str(score)+\"%\")\n",
        "      cv2.putText(image,text,(x1, y1 - 15),cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "     # cv2.rectangle(image, (x1, y1), (x2, int(y2*3)), (0, 0, 255), 2) # big bbox\n",
        "      #cv2.rectangle(img, (x1, y1), (x2, int(y2)), (0, 0, 255), 2)\n",
        "      #cv2.putText(image, \"ID Card :\"+, (0 + int(w/45),0 + int(h/16.5)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
        "    \n",
        "      net.setInput(cv2.dnn.blobFromImage(logo_imgCrop, 0.00392, (416,416), (0,0,0), True, crop=False))\n",
        "      layer_names = net.getLayerNames()\n",
        "\n",
        "      #output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "      output_layers = [layer_names[i-1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "      outs = net.forward(output_layers)\n",
        "      class_ids = []\n",
        "      confidences = []\n",
        "      boxes = []\n",
        "      Width = logo_imgCrop.shape[1]\n",
        "      Height = logo_imgCrop.shape[0]\n",
        "      \n",
        "      for out in outs:\n",
        "          for detection in out:\n",
        "              scores = detection[5:]\n",
        "              class_id = np.argmax(scores)\n",
        "              confidence = scores[class_id]\n",
        "              if confidence > 0.1:\n",
        "                  center_x = int(detection[0] * Width)\n",
        "                  center_y = int(detection[1] * Height)\n",
        "                  w = int(detection[2] * Width)\n",
        "                  h = int(detection[3] * Height)\n",
        "                  x = center_x - w / 2\n",
        "                  y = center_y - h / 2\n",
        "                  class_ids.append(class_id)\n",
        "                  confidences.append(float(confidence))\n",
        "                  boxes.append([x, y, w, h])\n",
        "      indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.1, 0.1)\n",
        "\n",
        "      for i in indices:\n",
        "          box = boxes[i]\n",
        "          x=round(box[0])\n",
        "          y=round(box[1])\n",
        "          w=round(box[2])\n",
        "          h=round(box[3])\n",
        "          new_y=round(box[1]*1)\n",
        "          new_h=round(box[3]*1.75)\n",
        "\n",
        "          if class_ids[i]==0:\n",
        "              label = str(classes[class_id]) \n",
        "              #cv2.rectangle(image, (x,y), (x+w,y+h), (0, 0, 0), 2)\n",
        "              #cv2.rectangle(logo_imgCrop, (x,new_y), (x+w+15,y+new_h), (0, 255, 0), 2)\n",
        "\n",
        "              #cv2.putText(logo_imgCrop, label, (round(box[0])-10,round(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
        "              imgCrop = logo_imgCrop[y:y + new_h, x:x + w+15]\n",
        "              #cropped_image = img_cropped[int(y2/3):y2*3, x1:x2]   \n",
        "              #mgCrop = image[y:y + new_h, x:x + w]\n",
        "              cv2_imshow(imgCrop)\n",
        "              ## (1) gray scale crop image \n",
        "              gray = cv2.cvtColor(imgCrop, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "              ## (2) Threshold\n",
        "              th, threshed = cv2.threshold(gray, 100, 255, cv2.THRESH_TRUNC)\n",
        "              cv2_imshow(threshed)\n",
        "              ## (3) Detect\n",
        "              result = pytesseract.image_to_string((threshed), lang=\"ind\")\n",
        "              print(result)\n",
        "              text_list=[]\n",
        "              ## (5) Normalize\n",
        "              for word in result.split(\"\\n\"):\n",
        "                if \"”—\" in word:\n",
        "                  word = word.replace(\"”—\", \":\")\n",
        "                \n",
        "                #normalize NIK\n",
        "                if \"NIK\" in word:\n",
        "                  nik_char = word.split()\n",
        "                  if \"D\" in word:\n",
        "                    word = word.replace(\"D\", \"0\")\n",
        "                  if \"?\" in word:\n",
        "                    word = word.replace(\"?\", \"7\") \n",
        "                print(word)\n",
        "                word_len=len(word)\n",
        "                print(word_len)\n",
        "                if word.isnumeric() and word_len > 4 :\n",
        "                  id_numbers_detected=\"Detected\"\n",
        "                  color2 = (125, 246, 55)\n",
        "                  detected_num =word\n",
        "                  cv2.putText(image, detected_num, (0 + int(Width/45),0 + int(Height/6.5)), cv2.FONT_HERSHEY_SIMPLEX, 1, (125, 246, 55), 2, cv2.LINE_AA)\n",
        "\n",
        "                  print(\"Number detected\")\n",
        "                else :\n",
        "                  \n",
        "                  print(\"No Number detected\")\n",
        "\n",
        "\n",
        "  #print(word)\n",
        "#print(text_list)\n",
        "    cv2.putText(image, \"ID Card: \"+Card_detected, (0 + int(Width/45),0 + int(Height/22.5)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
        "    cv2.putText(image, \"ID Number: \"+id_numbers_detected, (0 + int(Width/45),0 + int(Height/9.5)), cv2.FONT_HERSHEY_SIMPLEX, 1, color2, 2, cv2.LINE_AA)\n",
        "\n",
        "    cv2_imshow(image)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usrd2xFKWPJL"
      },
      "source": [
        "▶ view the video "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAnP4R0xWPwp"
      },
      "outputs": [],
      "source": [
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "video = '/content/drive/MyDrive/Colab Notebooks/id_detection/WIN_20220830_08_48_07_Pro.mp4'  \n",
        "\n",
        "video_path = video ######## put the name of your video file HERE\n",
        "\n",
        "mp4 = open(video_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRZeWmk_Yeqa"
      },
      "source": [
        "▶ video detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r2899ckYQ93",
        "outputId": "ab649be8-0e37-43cf-aaf8-6803b38bd5dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video resolution :  288 352\n",
            "50 processed frames\n",
            "100 processed frames\n",
            "150 processed frames\n",
            "200 processed frames\n",
            "250 processed frames\n",
            "300 processed frames\n",
            "350 processed frames\n",
            "400 processed frames\n",
            "450 processed frames\n",
            "500 processed frames\n",
            "550 processed frames\n",
            "600 processed frames\n",
            "650 processed frames\n",
            "700 processed frames\n",
            "750 processed frames\n",
            "800 processed frames\n",
            "850 processed frames\n",
            "900 processed frames\n",
            "950 processed frames\n",
            "1000 processed frames\n",
            "1050 processed frames\n",
            "1100 processed frames\n",
            "1150 processed frames\n",
            "1200 processed frames\n",
            "1250 processed frames\n",
            "1300 processed frames\n",
            "1350 processed frames\n",
            "1400 processed frames\n",
            "1450 processed frames\n",
            "1500 processed frames\n",
            "Videosaved as /content/drive/MyDrive/Colab Notebooks/id_detection/WIN_20220901_12_59_50_Pro_id_detection_vid2.mp4\n",
            "Total time elapsed: 14898.349 segundos\n"
          ]
        }
      ],
      "source": [
        "classes = None\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/id_detection/coco.names.txt\", \"r\") as f:\n",
        "  classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Video \n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "video = '/content/drive/MyDrive/Colab Notebooks/id_detection/WIN_20220901_12_59_50_Pro.mp4'  \n",
        "start = time.time()\n",
        "cap = cv2.VideoCapture(video)\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "print(\"Video resolution : \", height, width)\n",
        "assert cap.isOpened(), 'Cannot capture source'\n",
        "#Add extension mask_rcnn to video name\n",
        "video_detection_path =  video.split(\".\")[0] + \"_id_detection_vid2.\" + video.split(\".\")[1]\n",
        "\n",
        "\n",
        "#Video save\n",
        "videoSaved = cv2.VideoWriter(video_detection_path, apiPreference=cv2.CAP_FFMPEG,\n",
        "                             fourcc = fourcc,fps =20, frameSize=(width, height),\t\n",
        "                             isColor= True)\n",
        "frames = 0\n",
        "net = cv2.dnn.readNet('/content/drive/MyDrive/Colab Notebooks/Mask-R-CNN/Mask_RCNN-master/yolov3.weights', '/content/drive/MyDrive/Colab Notebooks/id_detection/yolov3.cfg.txt')\n",
        "\n",
        "while cap.isOpened():\n",
        "    Card_detected=\"Not Detected\"\n",
        "    color = (0, 0, 255)\n",
        "    id_numbers_detected=\"Not Detected\"\n",
        "    color2 = (0, 0, 255)\n",
        "    ret, frame = cap.read()\n",
        "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "#for imagePath in glob.glob(\"/content/drive/MyDrive/Colab Notebooks/id_detection/test\"+ \"/*.jpeg\"):\n",
        "  #  image = cv2.imread(imagePath)\n",
        "    #(h,w)=image.shape[:2]\n",
        "    if ret:    \n",
        "        img = img_to_array(frame)\n",
        "        # detecting objects in the image\n",
        "        result= model.detect([img])\n",
        "        r = result[0]\n",
        "        #print(r)\n",
        "        class_name=\"western digital id\"\n",
        "        found = None\n",
        "        if r[\"scores\"].any():\n",
        "\n",
        "          Detection_text=\"Detected\"\n",
        "          an_array = np.array(r[\"scores\"])\n",
        "          index = np.argmax(an_array)\n",
        "          y1, x1, y2, x2=tuple(r[\"rois\"][index])\n",
        "          logo_imgCrop = frame[y1:y2*3, x1:x2]\n",
        "          #cv2_imshow(logo_imgCrop)\n",
        "          #visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'], test.class_names, r['scores'],title=\"Predictions\")\n",
        "          score = round(r[\"scores\"][index]*100, 2) \n",
        "          #if score >= 85:\n",
        "          Card_detected=\"Detected\"\n",
        "          color = (125, 246, 55)\n",
        "          text=str(class_name +\"  \"+str(score)+\"%\")\n",
        "          cv2.putText(frame,text,(x1, y1 - 8), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.9, (255, 0, 0), 1,cv2.LINE_AA)\n",
        "          cv2.rectangle(frame, (x1, y1), (x2, int(y2*3)), (255, 0, 0), 2) # big bbox\n",
        "          #cv2.rectangle(img, (x1, y1), (x2, int(y2)), (0, 0, 255), 2)\n",
        "          #cv2.putText(image, \"ID Card :\"+, (0 + int(w/45),0 + int(h/16.5)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
        "        \n",
        "          net.setInput(cv2.dnn.blobFromImage(logo_imgCrop, 0.00392, (416,416), (0,0,0), True, crop=False))\n",
        "          layer_names = net.getLayerNames()\n",
        "\n",
        "          #output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "          output_layers = [layer_names[i-1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "          outs = net.forward(output_layers)\n",
        "          class_ids = []\n",
        "          confidences = []\n",
        "          boxes = []\n",
        "          Width_ = logo_imgCrop.shape[1]\n",
        "          Height_ = logo_imgCrop.shape[0]\n",
        "          \n",
        "          for out in outs:\n",
        "              for detection in out:\n",
        "                  scores = detection[5:]\n",
        "                  class_id = np.argmax(scores)\n",
        "                  confidence = scores[class_id]\n",
        "                  if confidence > 0.1:\n",
        "                      center_x = int(detection[0] * Width_)\n",
        "                      center_y = int(detection[1] * Height_)\n",
        "                      w = int(detection[2] * Width_)\n",
        "                      h = int(detection[3] * Height_)\n",
        "                      x = center_x - w / 2\n",
        "                      y = center_y - h / 2\n",
        "                      class_ids.append(class_id)\n",
        "                      confidences.append(float(confidence))\n",
        "                      boxes.append([x, y, w, h])\n",
        "          indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.1, 0.1)\n",
        "          if len(indices) > 0 :\n",
        "              for i in indices:\n",
        "                  box = boxes[i]\n",
        "                  x=round(box[0])\n",
        "                  y=round(box[1])\n",
        "                  w=round(box[2])\n",
        "                  h=round(box[3])\n",
        "                  if x  >= 0 :\n",
        "                    new_y=round(box[1]*1)\n",
        "                    new_h=round(box[3]*1.75)\n",
        "\n",
        "                    if class_ids[i]==0:\n",
        "                        label = str(classes[class_id]) \n",
        "                        #cv2.rectangle(image, (x,y), (x+w,y+h), (0, 0, 0), 2)\n",
        "                       # cv2.rectangle(logo_imgCrop, (x,new_y), (x+w+15,y+new_h), (0, 255, 0), 2)\n",
        "\n",
        "                        #cv2.putText(logo_imgCrop, label, (round(box[0])-10,round(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
        "                        imgCrop = logo_imgCrop[y:y + new_h, x:x + w+15]\n",
        "                        #cropped_image = img_cropped[int(y2/3):y2*3, x1:x2]   \n",
        "                        #mgCrop = image[y:y + new_h, x:x + w]\n",
        "                        #cv2_imshow(imgCrop)\n",
        "                        ## (1) gray scale crop image \n",
        "                        gray = cv2.cvtColor(imgCrop, cv2.COLOR_BGR2GRAY)\n",
        "                        #cv2_imshow(gray)\n",
        "\n",
        "                        ## (2) Threshold\n",
        "                        th, threshed = cv2.threshold(gray, 80, 255, cv2.THRESH_TRUNC)\n",
        "                        ## (3) Detect\n",
        "                        result = pytesseract.image_to_string((gray), lang=\"ind\")\n",
        "                        #print(result)\n",
        "                        text_list=[]\n",
        "                        ## (5) Normalize\n",
        "                        for word in result.split(\"\\n\"):\n",
        "                          if \"”—\" in word:\n",
        "                            word = word.replace(\"”—\", \":\")\n",
        "                          \n",
        "                          #normalize NIK\n",
        "                          if \"NIK\" in word:\n",
        "                            nik_char = word.split()\n",
        "                            if \"D\" in word:\n",
        "                              word = word.replace(\"D\", \"0\")\n",
        "                            if \"?\" in word:\n",
        "                              word = word.replace(\"?\", \"7\") \n",
        "                         # print(word)\n",
        "                          word_len=len(word)\n",
        "                          #print(word_len)\n",
        "                          if word.isnumeric() and word_len > 4 :\n",
        "                            id_numbers_detected=\"Detected\"\n",
        "                            color2 = (125, 246, 55)\n",
        "                            detected_num =word\n",
        "                            #cv2.putText(frame,detected_num,(x1, y1 - 15), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.9, (255, 0, 0), 1,cv2.LINE_AA)\n",
        "\n",
        "                            cv2.putText(frame, detected_num, (0 + int(width/45),0 + int(height/1.3)), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.9, (125, 246, 55), 1,cv2.LINE_AA)\n",
        "\n",
        "                          # print(\"Number detected\")\n",
        "                        #  else :\n",
        "                            \n",
        "                          #  print(\"No Number detected\")\n",
        "                  else :\n",
        "                      continue    \n",
        "\n",
        "\n",
        "      #print(word)\n",
        "    #print(text_list)\n",
        "       # scale = 1 # this value can be from 0 to 1 (0,1] to change the size of the text relative to the image\n",
        "       # fontScale = min(imageWidth,imageHeight)/(25/scale)\n",
        "        cv2.putText(frame, \"ID Card: \"+Card_detected, (0 + int(width/45),0 + int(height/1.02)), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.9, color, 1,cv2.LINE_AA)\n",
        "        cv2.putText(frame, \"ID Number: \"+id_numbers_detected, (0 + int(width/45),0 + int(height/1.1)), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.9, color2, 1,cv2.LINE_AA)\n",
        "        #cv2_imshow(frame)\n",
        "          # video save line\n",
        "        videoSaved.write(frame)\n",
        "          \n",
        "        frames += 1\n",
        "        if frames%50 == 0: print(\"{} processed frames\".format(frames))       \n",
        "    else :\n",
        "        break\n",
        "videoSaved.release()\n",
        "end = time.time()\n",
        "print(\"Videosaved as \" + video_detection_path)\n",
        "print('Total time elapsed: {:.3f} segundos'.format((end - start)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1s0oRLLh6PCP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}